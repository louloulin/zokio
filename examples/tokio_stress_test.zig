//! Tokioå‹åŠ›æµ‹è¯•ç¨‹åº
//!
//! æ‰§è¡ŒçœŸå®çš„Tokioå‹æµ‹å¹¶åˆ†ææ€§èƒ½æ•°æ®

const std = @import("std");
const zokio = @import("zokio");

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("=== Tokio å‹åŠ›æµ‹è¯•ä¸æ€§èƒ½åˆ†æ ===\n", .{});

    // æ£€æŸ¥Rustç¯å¢ƒ
    const runner = zokio.bench.tokio_runner.TokioRunner.init(allocator, null);
    const has_rust = checkRustEnvironment();

    if (!has_rust) {
        std.debug.print("âŒ æœªæ£€æµ‹åˆ°Rust/Cargoç¯å¢ƒ\n", .{});
        std.debug.print("è¯·å®‰è£…Rust: https://rustup.rs/\n", .{});
        std.debug.print("ä½¿ç”¨åŸºäºæ–‡çŒ®çš„åŸºå‡†æ•°æ®è¿›è¡Œæ¼”ç¤º...\n", .{});
        try demonstrateWithLiteratureData(allocator, &runner);
        return;
    }

    std.debug.print("âœ… æ£€æµ‹åˆ°Rustç¯å¢ƒï¼Œå¼€å§‹çœŸå®Tokioå‹æµ‹\n", .{});

    // æ‰§è¡Œå‹åŠ›æµ‹è¯•
    try runStressTests(allocator, &runner);
}

/// æ£€æŸ¥Rustç¯å¢ƒ
fn checkRustEnvironment() bool {
    const result = std.process.Child.run(.{
        .allocator = std.heap.page_allocator,
        .argv = &[_][]const u8{ "cargo", "--version" },
        .cwd = null,
    }) catch return false;

    defer std.heap.page_allocator.free(result.stdout);
    defer std.heap.page_allocator.free(result.stderr);

    return result.term == .Exited and result.term.Exited == 0;
}

/// è¿è¡Œå‹åŠ›æµ‹è¯•
fn runStressTests(allocator: std.mem.Allocator, runner: *const zokio.bench.tokio_runner.TokioRunner) !void {
    std.debug.print("\nğŸš€ å¼€å§‹Tokioå‹åŠ›æµ‹è¯•...\n", .{});

    // æµ‹è¯•é…ç½®
    const test_configs = [_]TestConfig{
        TestConfig{ .name = "è½»è´Ÿè½½", .iterations = 1000, .description = "1Kä»»åŠ¡" },
        TestConfig{ .name = "ä¸­è´Ÿè½½", .iterations = 10000, .description = "10Kä»»åŠ¡" },
        TestConfig{ .name = "é‡è´Ÿè½½", .iterations = 50000, .description = "50Kä»»åŠ¡" },
        TestConfig{ .name = "æé™è´Ÿè½½", .iterations = 100000, .description = "100Kä»»åŠ¡" },
    };

    const test_types = [_]TestType{
        TestType{ .bench_type = .task_scheduling, .name = "ä»»åŠ¡è°ƒåº¦", .description = "spawnå¤§é‡å¼‚æ­¥ä»»åŠ¡" },
        TestType{ .bench_type = .io_operations, .name = "I/Oæ“ä½œ", .description = "å¼‚æ­¥I/Oæ“ä½œ" },
        TestType{ .bench_type = .memory_allocation, .name = "å†…å­˜åˆ†é…", .description = "å¼‚æ­¥å†…å­˜åˆ†é…" },
    };

    var results = std.ArrayList(StressTestResult).init(allocator);
    defer results.deinit();

    // æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ç»„åˆ
    for (test_types) |test_type| {
        std.debug.print("\nğŸ“Š æµ‹è¯•ç±»å‹: {s} ({s})\n", .{ test_type.name, test_type.description });

        for (test_configs) |config| {
            std.debug.print("  ğŸ”„ {s} - {s}...", .{ config.name, config.description });

            const start_time = std.time.nanoTimestamp();
            const metrics = runner.runBenchmark(test_type.bench_type, config.iterations) catch |err| {
                std.debug.print(" âŒ å¤±è´¥: {}\n", .{err});
                continue;
            };
            const end_time = std.time.nanoTimestamp();

            const result = StressTestResult{
                .test_type = test_type,
                .config = config,
                .metrics = metrics,
                .wall_time_ns = @as(u64, @intCast(end_time - start_time)),
            };

            try results.append(result);

            std.debug.print(" âœ… å®Œæˆ\n", .{});
            std.debug.print("    ååé‡: {d:.0} ops/sec\n", .{metrics.throughput_ops_per_sec});
            std.debug.print("    å¹³å‡å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(metrics.avg_latency_ns)) / 1000.0});
        }
    }

    // åˆ†æç»“æœ
    try analyzeResults(allocator, results.items);
}

/// ä½¿ç”¨æ–‡çŒ®æ•°æ®æ¼”ç¤º
fn demonstrateWithLiteratureData(allocator: std.mem.Allocator, runner: *const zokio.bench.tokio_runner.TokioRunner) !void {
    std.debug.print("\nğŸ“š ä½¿ç”¨åŸºäºæ–‡çŒ®çš„TokioåŸºå‡†æ•°æ®æ¼”ç¤º\n", .{});

    const test_types = [_]zokio.bench.BenchType{
        .task_scheduling,
        .io_operations,
        .memory_allocation,
        .network_operations,
        .filesystem_operations,
        .future_composition,
        .concurrency,
    };

    const type_names = [_][]const u8{
        "ä»»åŠ¡è°ƒåº¦",
        "I/Oæ“ä½œ",
        "å†…å­˜åˆ†é…",
        "ç½‘ç»œæ“ä½œ",
        "æ–‡ä»¶ç³»ç»Ÿæ“ä½œ",
        "Futureç»„åˆ",
        "å¹¶å‘æ“ä½œ",
    };

    var results = std.ArrayList(LiteratureResult).init(allocator);
    defer results.deinit();

    for (test_types, type_names) |test_type, name| {
        const metrics = runner.getLiteratureBaseline(test_type);
        const result = LiteratureResult{
            .name = name,
            .bench_type = test_type,
            .metrics = metrics,
        };
        try results.append(result);

        std.debug.print("\nğŸ“ˆ {s}:\n", .{name});
        std.debug.print("  ååé‡: {d:.0} ops/sec\n", .{metrics.throughput_ops_per_sec});
        std.debug.print("  å¹³å‡å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(metrics.avg_latency_ns)) / 1000.0});
        std.debug.print("  P95å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(metrics.p95_latency_ns)) / 1000.0});
        std.debug.print("  P99å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(metrics.p99_latency_ns)) / 1000.0});
    }

    // ç”Ÿæˆåˆ†ææŠ¥å‘Š
    try generateLiteratureAnalysis(results.items);
}

/// åˆ†æå‹æµ‹ç»“æœ
fn analyzeResults(allocator: std.mem.Allocator, results: []const StressTestResult) !void {
    std.debug.print("\n" ++ "=" ** 60 ++ "\n", .{});
    std.debug.print("Tokio å‹åŠ›æµ‹è¯•æ€§èƒ½åˆ†ææŠ¥å‘Š\n", .{});
    std.debug.print("=" ** 60 ++ "\n", .{});

    // æŒ‰æµ‹è¯•ç±»å‹åˆ†ç»„åˆ†æ
    const test_types = [_]zokio.bench.BenchType{ .task_scheduling, .io_operations, .memory_allocation };
    const type_names = [_][]const u8{ "ä»»åŠ¡è°ƒåº¦", "I/Oæ“ä½œ", "å†…å­˜åˆ†é…" };

    for (test_types, type_names) |test_type, type_name| {
        std.debug.print("\nğŸ“Š {s} æ€§èƒ½åˆ†æ:\n", .{type_name});

        // æ”¶é›†è¯¥ç±»å‹çš„æ‰€æœ‰ç»“æœ
        var type_results = std.ArrayList(StressTestResult).init(allocator);
        defer type_results.deinit();

        for (results) |result| {
            if (result.test_type.bench_type == test_type) {
                try type_results.append(result);
            }
        }

        if (type_results.items.len == 0) continue;

        // åˆ†ææ€§èƒ½è¶‹åŠ¿
        try analyzePerformanceTrend(type_results.items, type_name);

        // åˆ†æç“¶é¢ˆ
        try analyzeBottlenecks(type_results.items, type_name);
    }

    // ç”Ÿæˆç»¼åˆå»ºè®®
    try generateRecommendations(results);
}

/// åˆ†ææ€§èƒ½è¶‹åŠ¿
fn analyzePerformanceTrend(results: []const StressTestResult, type_name: []const u8) !void {
    _ = type_name;
    std.debug.print("  ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿åˆ†æ:\n", .{});

    for (results, 0..) |result, i| {
        const load_factor = @as(f64, @floatFromInt(result.config.iterations)) / 1000.0;
        const efficiency = result.metrics.throughput_ops_per_sec / load_factor;

        std.debug.print("    {s}: {d:.0} ops/sec (æ•ˆç‡: {d:.0})\n", .{
            result.config.name,
            result.metrics.throughput_ops_per_sec,
            efficiency,
        });

        if (i > 0) {
            const prev_result = results[i - 1];
            const throughput_change = (result.metrics.throughput_ops_per_sec / prev_result.metrics.throughput_ops_per_sec - 1.0) * 100.0;
            const latency_change = (@as(f64, @floatFromInt(result.metrics.avg_latency_ns)) / @as(f64, @floatFromInt(prev_result.metrics.avg_latency_ns)) - 1.0) * 100.0;

            std.debug.print("      vs {s}: ååé‡ {s}{d:.1}%, å»¶è¿Ÿ {s}{d:.1}%\n", .{
                prev_result.config.name,
                if (throughput_change >= 0) "+" else "",
                throughput_change,
                if (latency_change >= 0) "+" else "",
                latency_change,
            });
        }
    }
}

/// åˆ†ææ€§èƒ½ç“¶é¢ˆ
fn analyzeBottlenecks(results: []const StressTestResult, type_name: []const u8) !void {
    _ = type_name;
    std.debug.print("  ğŸ” ç“¶é¢ˆåˆ†æ:\n", .{});

    // æ‰¾åˆ°æ€§èƒ½ä¸‹é™æœ€ä¸¥é‡çš„ç‚¹
    var max_degradation: f64 = 0;
    var bottleneck_point: ?StressTestResult = null;

    for (results, 1..) |result, i| {
        if (i >= results.len) break;

        const prev_result = results[i - 1];
        const expected_throughput = prev_result.metrics.throughput_ops_per_sec *
            (@as(f64, @floatFromInt(result.config.iterations)) / @as(f64, @floatFromInt(prev_result.config.iterations)));

        const actual_throughput = result.metrics.throughput_ops_per_sec;
        const degradation = (expected_throughput - actual_throughput) / expected_throughput;

        if (degradation > max_degradation) {
            max_degradation = degradation;
            bottleneck_point = result;
        }
    }

    if (bottleneck_point) |bp| {
        std.debug.print("    âš ï¸  ä¸»è¦ç“¶é¢ˆå‡ºç°åœ¨: {s}\n", .{bp.config.name});
        std.debug.print("    æ€§èƒ½ä¸‹é™: {d:.1}%\n", .{max_degradation * 100.0});

        // åˆ†æå¯èƒ½çš„åŸå› 
        if (bp.metrics.avg_latency_ns > 10000) { // > 10Î¼s
            std.debug.print("    å¯èƒ½åŸå› : é«˜å»¶è¿Ÿ ({d:.2} Î¼s)\n", .{@as(f64, @floatFromInt(bp.metrics.avg_latency_ns)) / 1000.0});
        }

        if (bp.config.iterations > 50000) {
            std.debug.print("    å¯èƒ½åŸå› : é«˜å¹¶å‘è´Ÿè½½è¶…è¿‡ç³»ç»Ÿå®¹é‡\n", .{});
        }
    } else {
        std.debug.print("    âœ… æœªå‘ç°æ˜æ˜¾ç“¶é¢ˆï¼Œæ€§èƒ½æ‰©å±•è‰¯å¥½\n", .{});
    }
}

/// ç”Ÿæˆä¼˜åŒ–å»ºè®®
fn generateRecommendations(results: []const StressTestResult) !void {
    std.debug.print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:\n", .{});

    var total_throughput: f64 = 0;
    var total_latency: u64 = 0;
    var high_latency_count: u32 = 0;

    for (results) |result| {
        total_throughput += result.metrics.throughput_ops_per_sec;
        total_latency += result.metrics.avg_latency_ns;

        if (result.metrics.avg_latency_ns > 5000) { // > 5Î¼s
            high_latency_count += 1;
        }
    }

    const avg_throughput = total_throughput / @as(f64, @floatFromInt(results.len));
    const avg_latency = total_latency / results.len;

    std.debug.print("  ğŸ“Š æ•´ä½“æ€§èƒ½æ¦‚å†µ:\n", .{});
    std.debug.print("    å¹³å‡ååé‡: {d:.0} ops/sec\n", .{avg_throughput});
    std.debug.print("    å¹³å‡å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency)) / 1000.0});

    std.debug.print("\n  ğŸ¯ ä¼˜åŒ–å»ºè®®:\n", .{});

    if (avg_throughput < 500_000) {
        std.debug.print("    â€¢ ååé‡è¾ƒä½ï¼Œè€ƒè™‘ä¼˜åŒ–ä»»åŠ¡è°ƒåº¦å™¨\n", .{});
        std.debug.print("    â€¢ æ£€æŸ¥æ˜¯å¦å­˜åœ¨é”ç«äº‰\n", .{});
    }

    if (avg_latency > 3000) { // > 3Î¼s
        std.debug.print("    â€¢ å¹³å‡å»¶è¿Ÿè¾ƒé«˜ï¼Œä¼˜åŒ–çƒ­è·¯å¾„ä»£ç \n", .{});
        std.debug.print("    â€¢ è€ƒè™‘å‡å°‘å†…å­˜åˆ†é…\n", .{});
    }

    if (high_latency_count > results.len / 2) {
        std.debug.print("    â€¢ å¤šæ•°æµ‹è¯•å»¶è¿Ÿè¾ƒé«˜ï¼Œå¯èƒ½éœ€è¦æ¶æ„ä¼˜åŒ–\n", .{});
    }

    std.debug.print("    â€¢ å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿›è¡Œæ›´é•¿æ—¶é—´çš„å‹æµ‹\n", .{});
    std.debug.print("    â€¢ ç›‘æ§å†…å­˜ä½¿ç”¨å’ŒGCå‹åŠ›\n", .{});
}

/// ç”Ÿæˆæ–‡çŒ®æ•°æ®åˆ†æ
fn generateLiteratureAnalysis(results: []const LiteratureResult) !void {
    std.debug.print("\n" ++ "=" ** 60 ++ "\n", .{});
    std.debug.print("Tokio åŸºå‡†æ€§èƒ½æ•°æ®åˆ†æ\n", .{});
    std.debug.print("=" ** 60 ++ "\n", .{});

    // æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®æ€§èƒ½
    var best_throughput: f64 = 0;
    var worst_latency: u64 = 0;
    var best_type: []const u8 = "";
    var worst_type: []const u8 = "";

    for (results) |result| {
        if (result.metrics.throughput_ops_per_sec > best_throughput) {
            best_throughput = result.metrics.throughput_ops_per_sec;
            best_type = result.name;
        }

        if (result.metrics.avg_latency_ns > worst_latency) {
            worst_latency = result.metrics.avg_latency_ns;
            worst_type = result.name;
        }
    }

    std.debug.print("ğŸ† æœ€ä½³ååé‡: {s} ({d:.0} ops/sec)\n", .{ best_type, best_throughput });
    std.debug.print("âš ï¸  æœ€é«˜å»¶è¿Ÿ: {s} ({d:.2} Î¼s)\n", .{ worst_type, @as(f64, @floatFromInt(worst_latency)) / 1000.0 });

    std.debug.print("\nğŸ“‹ æ€§èƒ½ç‰¹å¾æ€»ç»“:\n", .{});
    std.debug.print("  â€¢ Tokioåœ¨Futureç»„åˆæ–¹é¢è¡¨ç°æœ€ä½³\n", .{});
    std.debug.print("  â€¢ æ–‡ä»¶ç³»ç»Ÿæ“ä½œå»¶è¿Ÿç›¸å¯¹è¾ƒé«˜\n", .{});
    std.debug.print("  â€¢ ä»»åŠ¡è°ƒåº¦æ€§èƒ½å‡è¡¡ï¼Œé€‚åˆé«˜å¹¶å‘åœºæ™¯\n", .{});
}

// æ•°æ®ç»“æ„å®šä¹‰
const TestConfig = struct {
    name: []const u8,
    iterations: u32,
    description: []const u8,
};

const TestType = struct {
    bench_type: zokio.bench.BenchType,
    name: []const u8,
    description: []const u8,
};

const StressTestResult = struct {
    test_type: TestType,
    config: TestConfig,
    metrics: zokio.bench.PerformanceMetrics,
    wall_time_ns: u64,
};

const LiteratureResult = struct {
    name: []const u8,
    bench_type: zokio.bench.BenchType,
    metrics: zokio.bench.PerformanceMetrics,
};
