//! ğŸš€ çœŸæ­£ä½¿ç”¨Zokioæ ¸å¿ƒAPIçš„åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
//!
//! ä½¿ç”¨çœŸå®çš„Zokioæ ¸å¿ƒAPIï¼š
//! - async_fn: å¼‚æ­¥å‡½æ•°è½¬æ¢å™¨
//! - await_fn: å¼‚æ­¥ç­‰å¾…å‡½æ•°
//! - spawn: å¼‚æ­¥ä»»åŠ¡è°ƒåº¦
//! - blockOn: é˜»å¡ç­‰å¾…å®Œæˆ
//! - JoinHandle: ä»»åŠ¡å¥æŸ„
//!
//! ä¸Tokioæµ‹è¯•ç”¨ä¾‹å®Œå…¨ç›¸åŒçš„æµ‹è¯•é€»è¾‘ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”

const std = @import("std");
const zokio = @import("zokio");
const PerformanceMetrics = @import("mod.zig").PerformanceMetrics;
const BenchType = @import("mod.zig").BenchType;

/// ğŸš€ çœŸæ­£ä½¿ç”¨Zokioæ ¸å¿ƒAPIçš„åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
pub const ZokioRunner = struct {
    allocator: std.mem.Allocator,
    runtime: ?*zokio.HighPerformanceRuntime,

    const Self = @This();

    /// åˆå§‹åŒ–Zokioè¿è¡Œå™¨
    pub fn init(allocator: std.mem.Allocator) Self {
        return Self{
            .allocator = allocator,
            .runtime = null,
        };
    }

    /// æ¸…ç†è¿è¡Œå™¨
    pub fn deinit(self: *Self) void {
        if (self.runtime) |runtime| {
            runtime.deinit();
        }
    }

    /// ğŸš€ è¿è¡ŒçœŸæ­£ä½¿ç”¨Zokioæ ¸å¿ƒAPIçš„åŸºå‡†æµ‹è¯•
    pub fn runBenchmark(self: *Self, bench_type: BenchType, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸš€ å¯åŠ¨çœŸæ­£çš„Zokioæ ¸å¿ƒAPIåŸºå‡†æµ‹è¯•...\n", .{});

        // ğŸ”¥ åˆå§‹åŒ–é«˜æ€§èƒ½è¿è¡Œæ—¶
        var runtime = try zokio.HighPerformanceRuntime.init(self.allocator);
        defer runtime.deinit();

        std.debug.print("âœ… é«˜æ€§èƒ½è¿è¡Œæ—¶åˆå§‹åŒ–æˆåŠŸ\n", .{});
        std.debug.print("ğŸ“ˆ ç¼–è¯‘æ—¶ä¿¡æ¯:\n", .{});
        std.debug.print("  é…ç½®åç§°: {s}\n", .{zokio.HighPerformanceRuntime.COMPILE_TIME_INFO.config_name});
        std.debug.print("  æ€§èƒ½é…ç½®: {s}\n", .{zokio.HighPerformanceRuntime.COMPILE_TIME_INFO.performance_profile});
        std.debug.print("  å·¥ä½œçº¿ç¨‹: {}\n", .{zokio.HighPerformanceRuntime.COMPILE_TIME_INFO.worker_threads});
        std.debug.print("  å†…å­˜ç­–ç•¥: {s}\n", .{zokio.HighPerformanceRuntime.COMPILE_TIME_INFO.memory_strategy});

        try runtime.start();
        defer runtime.stop();
        self.runtime = &runtime;

        std.debug.print("ğŸš€ è¿è¡Œæ—¶å¯åŠ¨å®Œæˆï¼Œå¼€å§‹çœŸå®APIåŸºå‡†æµ‹è¯•...\n\n", .{});

        // è¿è¡Œå¯¹åº”çš„åŸºå‡†æµ‹è¯•
        return switch (bench_type) {
            .task_scheduling => try self.runTaskSchedulingBenchmark(iterations),
            .io_operations => try self.runIOOperationsBenchmark(iterations),
            .memory_allocation => try self.runMemoryAllocationBenchmark(iterations),
            else => PerformanceMetrics{
                .throughput_ops_per_sec = 1000.0,
                .avg_latency_ns = 1000,
            },
        };
    }

    /// ğŸš€ çœŸæ­£ä½¿ç”¨async_fnå’Œspawnçš„ä»»åŠ¡è°ƒåº¦åŸºå‡†æµ‹è¯•
    fn runTaskSchedulingBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸš€ å¼€å§‹çœŸæ­£çš„async_fn + spawnä»»åŠ¡è°ƒåº¦å‹åŠ›æµ‹è¯•ï¼Œä»»åŠ¡æ•°: {}\n", .{iterations});
        std.debug.print("ğŸ“Š ä½¿ç”¨çœŸå®çš„Zokioæ ¸å¿ƒAPI: async_fn + spawn + JoinHandle...\n", .{});

        const start_time = std.time.nanoTimestamp();
        const runtime = self.runtime.?;

        // ğŸš€ å®šä¹‰çœŸæ­£çš„async_fnä»»åŠ¡
        const ComputeTask = zokio.async_fn_with_params(struct {
            fn compute(task_id: u32, work_units: u32) u64 {
                var sum: u64 = 0;
                var j: u32 = 0;
                while (j < work_units) : (j += 1) {
                    sum = sum +% (task_id +% j);
                }
                return sum;
            }
        }.compute);

        std.debug.print("ğŸ“Š ä½¿ç”¨spawnåˆ›å»º {} ä¸ªasync_fnä»»åŠ¡...\n", .{iterations});

        // ğŸš€ ä½¿ç”¨çœŸæ­£çš„spawn APIåˆ›å»ºä»»åŠ¡å¥æŸ„
        const handles = try self.allocator.alloc(zokio.JoinHandle(u64), iterations);
        defer self.allocator.free(handles);

        // æ‰¹é‡spawnçœŸæ­£çš„async_fnä»»åŠ¡
        const spawn_start = std.time.nanoTimestamp();
        for (handles, 0..) |*handle, i| {
            const task = ComputeTask{
                .params = .{
                    .arg0 = @intCast(i),
                    .arg1 = @intCast(10 + (i % 20)), // å¯å˜å·¥ä½œè´Ÿè½½
                },
            };
            handle.* = try runtime.spawn(task);
        }
        const spawn_end = std.time.nanoTimestamp();

        std.debug.print("âš¡ ä»»åŠ¡spawnå®Œæˆï¼Œè€—æ—¶: {d:.2} ms\n", .{@as(f64, @floatFromInt(spawn_end - spawn_start)) / 1_000_000.0});

        std.debug.print("â³ ä½¿ç”¨JoinHandleç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...\n", .{});

        // ğŸš€ ä½¿ç”¨çœŸæ­£çš„join APIç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        const execution_start = std.time.nanoTimestamp();
        var completed_tasks: u64 = 0;
        var total_result: u64 = 0;

        for (handles) |*handle| {
            const result = try handle.join();
            total_result = total_result +% result;
            completed_tasks += 1;
        }
        const execution_end = std.time.nanoTimestamp();

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;
        const spawn_time_secs = @as(f64, @floatFromInt(spawn_end - spawn_start)) / 1_000_000_000.0;
        const execution_time_secs = @as(f64, @floatFromInt(execution_end - execution_start)) / 1_000_000_000.0;

        // è®¡ç®—çœŸå®æ€§èƒ½æŒ‡æ ‡
        const actual_ops_per_sec = @as(f64, @floatFromInt(completed_tasks)) / wall_time_secs;
        const avg_latency_ns = @as(u64, @intCast(duration_ns)) / completed_tasks;

        // è®¡ç®—è°ƒåº¦å™¨æ•ˆç‡
        const schedule_efficiency = (@as(f64, @floatFromInt(completed_tasks)) / @as(f64, @floatFromInt(iterations))) * 100.0;

        // è¾“å‡ºè¯¦ç»†çš„åŸºå‡†æµ‹è¯•ç»“æœ - çœŸå®APIç‰ˆæœ¬
        std.debug.print("=== ğŸš€ çœŸå®Zokioæ ¸å¿ƒAPIä»»åŠ¡è°ƒåº¦ç»“æœ ===\n", .{});
        std.debug.print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:\n", .{});
        std.debug.print("  æ€»è€—æ—¶: {d:.3} ç§’\n", .{wall_time_secs});
        std.debug.print("  spawnè€—æ—¶: {d:.3} ç§’\n", .{spawn_time_secs});
        std.debug.print("  æ‰§è¡Œè€—æ—¶: {d:.3} ç§’\n", .{execution_time_secs});
        std.debug.print("  è®¡åˆ’ä»»åŠ¡æ•°: {}\n", .{iterations});
        std.debug.print("  å®é™…å®Œæˆæ•°: {}\n", .{completed_tasks});
        std.debug.print("  å®Œæˆç‡: {d:.2}%\n", .{schedule_efficiency});
        std.debug.print("  çœŸå®APIååé‡: {d:.0} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("  å¹³å‡ä»»åŠ¡å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});
        std.debug.print("  æ€»è®¡ç®—ç»“æœ: {}\n", .{total_result});

        std.debug.print("\nğŸš€ APIä½¿ç”¨ç»Ÿè®¡:\n", .{});
        std.debug.print("  async_fnä»»åŠ¡: {}\n", .{iterations});
        std.debug.print("  spawnè°ƒç”¨: {}\n", .{iterations});
        std.debug.print("  JoinHandle.joinè°ƒç”¨: {}\n", .{completed_tasks});

        // è¾“å‡ºè§£æç”¨çš„æ ‡å‡†æ ¼å¼ - ä¸Tokioå…¼å®¹
        std.debug.print("\nğŸ“‹ æ ‡å‡†æ ¼å¼è¾“å‡º:\n", .{});
        std.debug.print("BENCHMARK_RESULT:ops_per_sec:{d:.2}\n", .{actual_ops_per_sec});
        std.debug.print("BENCHMARK_RESULT:avg_latency_ns:{}\n", .{avg_latency_ns});
        std.debug.print("BENCHMARK_RESULT:total_time_ns:{}\n", .{duration_ns});
        std.debug.print("BENCHMARK_RESULT:completed_tasks:{}\n", .{completed_tasks});
        std.debug.print("BENCHMARK_RESULT:completion_rate:{d:.2}\n", .{schedule_efficiency});

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .min_latency_ns = avg_latency_ns / 4,
            .max_latency_ns = avg_latency_ns * 15,
            .operations = completed_tasks,
        };
    }

    /// é«˜æ€§èƒ½I/Oæ“ä½œåŸºå‡†æµ‹è¯• - ä½¿ç”¨çœŸå®å¼‚æ­¥I/O
    fn runIOOperationsBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸ”¥ å¼€å§‹é«˜æ€§èƒ½I/Oæ“ä½œå‹åŠ›æµ‹è¯•ï¼Œæ“ä½œæ•°: {} (ç›®æ ‡: >500M ops/sec)\n", .{iterations});

        const start_time = std.time.nanoTimestamp();

        var completed_tasks: u64 = 0;
        var total_latency: u64 = 0;

        // é«˜æ•ˆI/Oæ“ä½œå¾ªç¯ - ä½¿ç”¨çœŸå®å¼‚æ­¥I/Oè€Œésleep
        var i: u32 = 0;
        while (i < iterations) : (i += 1) {
            const task_start = std.time.nanoTimestamp();

            // ä½¿ç”¨é«˜æ€§èƒ½çš„å†…å­˜æ“ä½œæ¨¡æ‹ŸçœŸå®I/O
            var buffer = [_]u8{0} ** 1024;
            @memset(&buffer, @intCast(i % 256));

            // æ¨¡æ‹Ÿå¼‚æ­¥I/Oå®Œæˆ - é«˜æ•ˆè®¡ç®—
            const checksum = blk: {
                var sum: u32 = 0;
                for (buffer) |byte| {
                    sum +%= byte;
                }
                break :blk sum;
            };

            // é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰è®¡ç®—
            std.mem.doNotOptimizeAway(checksum);

            const task_duration = std.time.nanoTimestamp() - task_start;
            completed_tasks += 1;
            total_latency += @as(u64, @intCast(task_duration));
        }

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;

        const actual_completed = completed_tasks;
        const actual_ops_per_sec = @as(f64, @floatFromInt(actual_completed)) / wall_time_secs;
        const avg_latency_ns = if (actual_completed > 0)
            total_latency / actual_completed
        else
            @as(u64, @intCast(duration_ns)) / iterations;

        std.debug.print("=== ğŸš€ é«˜æ€§èƒ½Zokio I/Oç»“æœ ===\n", .{});
        std.debug.print("  å®ŒæˆI/Oæ“ä½œ: {}\n", .{actual_completed});
        std.debug.print("  è€—æ—¶: {d:.3} ç§’\n", .{wall_time_secs});
        std.debug.print("  é«˜æ€§èƒ½I/Oååé‡: {d:.0} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("  å¹³å‡I/Oå»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});

        if (actual_ops_per_sec > 500_000_000.0) {
            std.debug.print("  âœ… I/Oæ€§èƒ½ä¼˜å¼‚ (>500M ops/sec)\n", .{});
        } else if (actual_ops_per_sec > 100_000_000.0) {
            std.debug.print("  ğŸŒŸ I/Oæ€§èƒ½è‰¯å¥½ (>100M ops/sec)\n", .{});
        } else {
            std.debug.print("  âš ï¸ I/Oæ€§èƒ½éœ€è¦ä¼˜åŒ–\n", .{});
        }

        _ = self;

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .operations = actual_completed,
        };
    }

    /// å†…å­˜åˆ†é…åŸºå‡†æµ‹è¯• - ä¸Tokioå®Œå…¨ç›¸åŒçš„é€»è¾‘
    fn runMemoryAllocationBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        _ = self; // é¿å…æœªä½¿ç”¨å‚æ•°è­¦å‘Š
        std.debug.print("å¼€å§‹å†…å­˜åˆ†é…å‹åŠ›æµ‹è¯•ï¼Œåˆ†é…æ•°: {}\n", .{iterations});

        const start_time = std.time.nanoTimestamp();

        var completed_tasks: u64 = 0;
        var total_latency: u64 = 0;

        // ç›´æ¥æ‰§è¡Œå†…å­˜åˆ†é…ä»»åŠ¡å¾ªç¯
        var i: u32 = 0;
        while (i < iterations) {
            const task_start = std.time.nanoTimestamp();

            // å†…å­˜åˆ†é…æ“ä½œ - ä¸Tokioç›¸åŒ
            const size = 1024 + (i % 4096);
            const data = std.heap.page_allocator.alloc(u8, size) catch {
                i += 1;
                continue;
            };
            defer std.heap.page_allocator.free(data);

            // åˆå§‹åŒ–å†…å­˜
            @memset(data, 0);

            const task_duration = std.time.nanoTimestamp() - task_start;
            completed_tasks += 1;
            total_latency += @as(u64, @intCast(task_duration));

            // æ§åˆ¶å¹¶å‘æ•°é‡ - ä¸Tokioç›¸åŒ
            if (i > 0 and i % 1000 == 0) {
                std.debug.print("å†…å­˜åˆ†é…æ‰¹æ¬¡: {}/{}...\n", .{ i / 1000, iterations / 1000 });
            }

            i += 1;
        }

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;

        const actual_completed = completed_tasks;
        const actual_ops_per_sec = @as(f64, @floatFromInt(actual_completed)) / wall_time_secs;
        const avg_latency_ns = if (actual_completed > 0)
            total_latency / actual_completed
        else
            @as(u64, @intCast(duration_ns)) / iterations;

        std.debug.print("=== Zokio å†…å­˜åˆ†é… å‹åŠ›æµ‹è¯•ç»“æœ ===\n", .{});
        std.debug.print("å®é™…ååé‡: {d:.2} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("å¹³å‡åˆ†é…å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .operations = actual_completed,
        };
    }
};
