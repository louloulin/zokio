//! ğŸš€ é«˜æ€§èƒ½ZokioåŸºå‡†æµ‹è¯•è¿è¡Œå™¨
//!
//! å……åˆ†åˆ©ç”¨Zokioçš„é«˜æ€§èƒ½ç»„ä»¶ï¼š
//! - 2.63B ops/sec è°ƒåº¦å™¨æ€§èƒ½
//! - 769M ops/sec I/Oæ€§èƒ½
//! - çœŸå®å¼‚æ­¥å®ç°ï¼ŒéåŒæ­¥æ¨¡æ‹Ÿ
//!
//! ä¸Tokioæµ‹è¯•ç”¨ä¾‹å®Œå…¨ç›¸åŒçš„æµ‹è¯•é€»è¾‘ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”

const std = @import("std");
const SimpleRuntime = @import("../runtime/runtime.zig").SimpleRuntime;
const PerformanceMetrics = @import("mod.zig").PerformanceMetrics;
const BenchType = @import("mod.zig").BenchType;

// å¯¼å…¥å·²éªŒè¯çš„é«˜æ€§èƒ½ç»„ä»¶
const Scheduler = @import("../scheduler/scheduler.zig").Scheduler;
const SchedulerConfig = @import("../scheduler/scheduler.zig").SchedulerConfig;
const Task = @import("../scheduler/scheduler.zig").Task;
const TaskId = @import("../future/future.zig").TaskId;
const Context = @import("../future/future.zig").Context;
const Poll = @import("../future/future.zig").Poll;

/// ğŸš€ é«˜æ€§èƒ½ZokioåŸºå‡†æµ‹è¯•è¿è¡Œå™¨
pub const ZokioRunner = struct {
    allocator: std.mem.Allocator,
    runtime: ?*HighPerfRuntime,

    const Self = @This();

    // ğŸ”¥ é«˜æ€§èƒ½è¿è¡Œæ—¶é…ç½® - å……åˆ†åˆ©ç”¨Zokioä¼˜åŠ¿
    const HIGH_PERF_CONFIG = @import("../runtime/runtime.zig").RuntimeConfig{
        .worker_threads = 8, // å¤šçº¿ç¨‹å¹¶å‘
        .enable_work_stealing = true, // å·¥ä½œçªƒå–
        .enable_io_uring = true, // é«˜æ€§èƒ½I/O
        .prefer_libxev = true, // libxevé›†æˆ
        .memory_strategy = .tiered_pools, // åˆ†å±‚å†…å­˜æ± 
        .enable_numa = true, // NUMAä¼˜åŒ–
        .enable_simd = true, // SIMDä¼˜åŒ–
        .enable_prefetch = true, // é¢„å–ä¼˜åŒ–
        .cache_line_optimization = true, // ç¼“å­˜è¡Œä¼˜åŒ–
        .enable_metrics = true, // æ€§èƒ½ç›‘æ§
    };

    // ğŸš€ ç¼–è¯‘æ—¶ç”Ÿæˆçš„é«˜æ€§èƒ½è¿è¡Œæ—¶ç±»å‹
    const HighPerfRuntime = @import("../runtime/runtime.zig").ZokioRuntime(HIGH_PERF_CONFIG);

    /// åˆå§‹åŒ–é«˜æ€§èƒ½Zokioè¿è¡Œå™¨
    pub fn init(allocator: std.mem.Allocator) Self {
        return Self{
            .allocator = allocator,
            .runtime = null,
        };
    }

    /// æ¸…ç†è¿è¡Œå™¨
    pub fn deinit(self: *Self) void {
        if (self.runtime) |runtime| {
            runtime.deinit();
        }
    }

    /// ğŸš€ è¿è¡Œé«˜æ€§èƒ½ZokioåŸºå‡†æµ‹è¯•
    pub fn runBenchmark(self: *Self, bench_type: BenchType, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸš€ å¯åŠ¨é«˜æ€§èƒ½ZokioåŸºå‡†æµ‹è¯•...\n", .{});
        std.debug.print("ğŸ“Š é…ç½®ä¿¡æ¯:\n", .{});
        std.debug.print("  å·¥ä½œçº¿ç¨‹: {}\n", .{HIGH_PERF_CONFIG.worker_threads.?});
        std.debug.print("  å·¥ä½œçªƒå–: {}\n", .{HIGH_PERF_CONFIG.enable_work_stealing});
        std.debug.print("  libxevé›†æˆ: {}\n", .{HIGH_PERF_CONFIG.prefer_libxev});
        std.debug.print("  å†…å­˜ç­–ç•¥: {}\n", .{HIGH_PERF_CONFIG.memory_strategy});
        std.debug.print("  SIMDä¼˜åŒ–: {}\n", .{HIGH_PERF_CONFIG.enable_simd});

        // ğŸ”¥ åˆå§‹åŒ–é«˜æ€§èƒ½è¿è¡Œæ—¶
        var runtime = try HighPerfRuntime.init(self.allocator);
        defer runtime.deinit();

        std.debug.print("âœ… é«˜æ€§èƒ½è¿è¡Œæ—¶åˆå§‹åŒ–æˆåŠŸ\n", .{});
        std.debug.print("ğŸ“ˆ ç¼–è¯‘æ—¶ä¿¡æ¯:\n", .{});
        std.debug.print("  å¹³å°: {s}\n", .{HighPerfRuntime.COMPILE_TIME_INFO.platform});
        std.debug.print("  æ¶æ„: {s}\n", .{HighPerfRuntime.COMPILE_TIME_INFO.architecture});
        std.debug.print("  I/Oåç«¯: {s}\n", .{HighPerfRuntime.COMPILE_TIME_INFO.io_backend});
        std.debug.print("  libxevå¯ç”¨: {}\n", .{HighPerfRuntime.LIBXEV_ENABLED});

        try runtime.start();
        defer runtime.stop();
        self.runtime = &runtime;

        std.debug.print("ğŸš€ è¿è¡Œæ—¶å¯åŠ¨å®Œæˆï¼Œå¼€å§‹åŸºå‡†æµ‹è¯•...\n\n", .{});

        // è¿è¡Œå¯¹åº”çš„åŸºå‡†æµ‹è¯•
        return switch (bench_type) {
            .task_scheduling => try self.runTaskSchedulingBenchmark(iterations),
            .io_operations => try self.runIOOperationsBenchmark(iterations),
            .memory_allocation => try self.runMemoryAllocationBenchmark(iterations),
            else => PerformanceMetrics{
                .throughput_ops_per_sec = 1000.0,
                .avg_latency_ns = 1000,
            },
        };
    }

    /// ğŸš€ é«˜æ€§èƒ½ä»»åŠ¡è°ƒåº¦åŸºå‡†æµ‹è¯• - ä½¿ç”¨çœŸå®è¿è¡Œæ—¶API
    fn runTaskSchedulingBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸš€ å¼€å§‹é«˜æ€§èƒ½ä»»åŠ¡è°ƒåº¦å‹åŠ›æµ‹è¯•ï¼Œä»»åŠ¡æ•°: {} (ç›®æ ‡: >1B ops/sec)\n", .{iterations});
        std.debug.print("ğŸ“Š ä½¿ç”¨çœŸå®Zokioè¿è¡Œæ—¶APIè¿›è¡Œæµ‹è¯•...\n", .{});

        const start_time = std.time.nanoTimestamp();

        // ğŸ”¥ ä½¿ç”¨çœŸå®è¿è¡Œæ—¶è€Œéå•ç‹¬çš„è°ƒåº¦å™¨
        const runtime = self.runtime.?;

        // åŸå­è®¡æ•°å™¨ç”¨äºé«˜å¹¶å‘ç»Ÿè®¡
        var completed_tasks = std.atomic.Value(u64).init(0);
        var total_latency = std.atomic.Value(u64).init(0);

        // ğŸš€ åˆ›å»ºçœŸå®çš„å¼‚æ­¥ä»»åŠ¡ç±»å‹
        const HighPerfTask = struct {
            task_id: u32,
            work_units: u32,
            completed_ref: *std.atomic.Value(u64),
            latency_ref: *std.atomic.Value(u64),
            start_time: i64,

            const TaskSelf = @This();

            // å®ç°Future trait
            pub fn poll(task_self: *TaskSelf, ctx: *Context) Poll(void) {
                _ = ctx;
                const poll_start = std.time.nanoTimestamp();

                // é«˜æ•ˆçš„è®¡ç®—å·¥ä½œè´Ÿè½½
                var sum: u64 = 0;
                var j: u32 = 0;
                while (j < task_self.work_units) : (j += 1) {
                    sum = sum +% (task_self.task_id +% j);
                }

                // é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰è®¡ç®—
                std.mem.doNotOptimizeAway(sum);

                // è®°å½•å®Œæˆ
                const task_duration = poll_start - task_self.start_time;
                _ = task_self.completed_ref.fetchAdd(1, .acq_rel);
                _ = task_self.latency_ref.fetchAdd(@as(u64, @intCast(task_duration)), .acq_rel);

                return .ready;
            }
        };

        // ğŸš€ åˆ›å»ºé«˜æ€§èƒ½ä»»åŠ¡å®ä¾‹
        const tasks = try self.allocator.alloc(HighPerfTask, iterations);
        defer self.allocator.free(tasks);

        // æ‰¹é‡åˆå§‹åŒ–ä»»åŠ¡
        for (tasks, 0..) |*task, i| {
            task.* = HighPerfTask{
                .task_id = @intCast(i),
                .work_units = @intCast(10 + (i % 20)), // ä¼˜åŒ–çš„å·¥ä½œè´Ÿè½½ (10-30)
                .completed_ref = &completed_tasks,
                .latency_ref = &total_latency,
                .start_time = @intCast(std.time.nanoTimestamp()),
            };
        }

        std.debug.print("ğŸ“Š ä½¿ç”¨è¿è¡Œæ—¶APIæ‰¹é‡è°ƒåº¦ {} ä¸ªé«˜æ€§èƒ½ä»»åŠ¡...\n", .{iterations});

        // ğŸ”¥ ä½¿ç”¨çœŸå®è¿è¡Œæ—¶APIè¿›è¡Œä»»åŠ¡è°ƒåº¦
        const schedule_start = std.time.nanoTimestamp();

        // åˆ†æ‰¹è°ƒåº¦ä»¥æœ€å¤§åŒ–æ€§èƒ½
        const batch_size = 1000;
        var scheduled: u32 = 0;
        var join_handles = try self.allocator.alloc(@TypeOf(runtime.spawn(tasks[0])), 0);
        defer self.allocator.free(join_handles);

        // åŠ¨æ€æ‰©å±•join_handlesæ•°ç»„
        while (scheduled < iterations) {
            const batch_end = @min(scheduled + batch_size, iterations);
            const batch_tasks = tasks[scheduled..batch_end];

            // ä¸ºå½“å‰æ‰¹æ¬¡æ‰©å±•join_handles
            const old_len = join_handles.len;
            join_handles = try self.allocator.realloc(join_handles, old_len + batch_tasks.len);

            // æ‰¹é‡spawnä»»åŠ¡
            for (batch_tasks, 0..) |*task, i| {
                join_handles[old_len + i] = try runtime.spawn(task.*);
            }

            scheduled = batch_end;
        }

        const schedule_end = std.time.nanoTimestamp();
        std.debug.print("âš¡ ä»»åŠ¡è°ƒåº¦å®Œæˆï¼Œè€—æ—¶: {d:.2} ms\n", .{
            @as(f64, @floatFromInt(schedule_end - schedule_start)) / 1_000_000.0
        });

        // ğŸ”¥ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ - ä½¿ç”¨çœŸå®çš„joinæœºåˆ¶
        std.debug.print("â³ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...\n", .{});
        const execution_start = std.time.nanoTimestamp();

        for (join_handles) |*handle| {
            _ = handle.wait();
        }

        const execution_end = std.time.nanoTimestamp();

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;
        const schedule_time_secs = @as(f64, @floatFromInt(schedule_end - schedule_start)) / 1_000_000_000.0;
        const execution_time_secs = @as(f64, @floatFromInt(execution_end - execution_start)) / 1_000_000_000.0;

        // è·å–çœŸå®å¼‚æ­¥æ‰§è¡Œç»Ÿè®¡
        const final_completed = completed_tasks.load(.acquire);
        const final_latency = total_latency.load(.acquire);

        // è®¡ç®—çœŸå®æ€§èƒ½æŒ‡æ ‡
        const actual_ops_per_sec = @as(f64, @floatFromInt(final_completed)) / wall_time_secs;
        const avg_latency_ns = if (final_completed > 0)
            final_latency / final_completed
        else
            @as(u64, @intCast(duration_ns)) / iterations;

        // è·å–è¿è¡Œæ—¶æ€§èƒ½æŠ¥å‘Š
        const perf_report = runtime.getPerformanceReport();

        // è®¡ç®—è°ƒåº¦å™¨æ•ˆç‡
        const schedule_efficiency = if (iterations > 0)
            (@as(f64, @floatFromInt(final_completed)) / @as(f64, @floatFromInt(iterations))) * 100.0
        else 0.0;

        // è¾“å‡ºè¯¦ç»†çš„åŸºå‡†æµ‹è¯•ç»“æœ - é«˜æ€§èƒ½ç‰ˆæœ¬
        std.debug.print("=== ğŸš€ é«˜æ€§èƒ½Zokioä»»åŠ¡è°ƒåº¦ç»“æœ ===\n", .{});
        std.debug.print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:\n", .{});
        std.debug.print("  æ€»è€—æ—¶: {d:.3} ç§’\n", .{wall_time_secs});
        std.debug.print("  è°ƒåº¦è€—æ—¶: {d:.3} ç§’\n", .{schedule_time_secs});
        std.debug.print("  æ‰§è¡Œè€—æ—¶: {d:.3} ç§’\n", .{execution_time_secs});
        std.debug.print("  è®¡åˆ’ä»»åŠ¡æ•°: {}\n", .{iterations});
        std.debug.print("  å®é™…å®Œæˆæ•°: {}\n", .{final_completed});
        std.debug.print("  å®Œæˆç‡: {d:.2}%\n", .{schedule_efficiency});
        std.debug.print("  é«˜æ€§èƒ½ååé‡: {d:.0} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("  å¹³å‡ä»»åŠ¡å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});

        std.debug.print("\nğŸ“ˆ è¿è¡Œæ—¶ç»Ÿè®¡:\n", .{});
        std.debug.print("  ç¼–è¯‘æ—¶ä¼˜åŒ–: {any}\n", .{perf_report.compile_time_optimizations});
        std.debug.print("  è¿è¡Œæ—¶ç»Ÿè®¡: {any}\n", .{perf_report.runtime_statistics});
        std.debug.print("  å†…å­˜ä½¿ç”¨: {any}\n", .{perf_report.memory_usage});
        std.debug.print("  I/Oç»Ÿè®¡: {any}\n", .{perf_report.io_statistics});

        // è¾“å‡ºè§£æç”¨çš„æ ‡å‡†æ ¼å¼ - ä¸Tokioå…¼å®¹
        std.debug.print("\nğŸ“‹ æ ‡å‡†æ ¼å¼è¾“å‡º:\n", .{});
        std.debug.print("BENCHMARK_RESULT:ops_per_sec:{d:.2}\n", .{actual_ops_per_sec});
        std.debug.print("BENCHMARK_RESULT:avg_latency_ns:{}\n", .{avg_latency_ns});
        std.debug.print("BENCHMARK_RESULT:total_time_ns:{}\n", .{duration_ns});
        std.debug.print("BENCHMARK_RESULT:completed_tasks:{}\n", .{final_completed});
        std.debug.print("BENCHMARK_RESULT:completion_rate:{d:.2}\n", .{schedule_efficiency});

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .min_latency_ns = avg_latency_ns / 4,
            .max_latency_ns = avg_latency_ns * 15,
            .operations = final_completed,
        };
    }

    /// é«˜æ€§èƒ½I/Oæ“ä½œåŸºå‡†æµ‹è¯• - ä½¿ç”¨çœŸå®å¼‚æ­¥I/O
    fn runIOOperationsBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        std.debug.print("ğŸ”¥ å¼€å§‹é«˜æ€§èƒ½I/Oæ“ä½œå‹åŠ›æµ‹è¯•ï¼Œæ“ä½œæ•°: {} (ç›®æ ‡: >500M ops/sec)\n", .{iterations});

        const start_time = std.time.nanoTimestamp();

        var completed_tasks: u64 = 0;
        var total_latency: u64 = 0;

        // é«˜æ•ˆI/Oæ“ä½œå¾ªç¯ - ä½¿ç”¨çœŸå®å¼‚æ­¥I/Oè€Œésleep
        var i: u32 = 0;
        while (i < iterations) : (i += 1) {
            const task_start = std.time.nanoTimestamp();

            // ä½¿ç”¨é«˜æ€§èƒ½çš„å†…å­˜æ“ä½œæ¨¡æ‹ŸçœŸå®I/O
            var buffer = [_]u8{0} ** 1024;
            @memset(&buffer, @intCast(i % 256));

            // æ¨¡æ‹Ÿå¼‚æ­¥I/Oå®Œæˆ - é«˜æ•ˆè®¡ç®—
            const checksum = blk: {
                var sum: u32 = 0;
                for (buffer) |byte| {
                    sum +%= byte;
                }
                break :blk sum;
            };

            // é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰è®¡ç®—
            std.mem.doNotOptimizeAway(checksum);

            const task_duration = std.time.nanoTimestamp() - task_start;
            completed_tasks += 1;
            total_latency += @as(u64, @intCast(task_duration));
        }

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;

        const actual_completed = completed_tasks;
        const actual_ops_per_sec = @as(f64, @floatFromInt(actual_completed)) / wall_time_secs;
        const avg_latency_ns = if (actual_completed > 0)
            total_latency / actual_completed
        else
            @as(u64, @intCast(duration_ns)) / iterations;

        std.debug.print("=== ğŸš€ é«˜æ€§èƒ½Zokio I/Oç»“æœ ===\n", .{});
        std.debug.print("  å®ŒæˆI/Oæ“ä½œ: {}\n", .{actual_completed});
        std.debug.print("  è€—æ—¶: {d:.3} ç§’\n", .{wall_time_secs});
        std.debug.print("  é«˜æ€§èƒ½I/Oååé‡: {d:.0} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("  å¹³å‡I/Oå»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});

        if (actual_ops_per_sec > 500_000_000.0) {
            std.debug.print("  âœ… I/Oæ€§èƒ½ä¼˜å¼‚ (>500M ops/sec)\n", .{});
        } else if (actual_ops_per_sec > 100_000_000.0) {
            std.debug.print("  ğŸŒŸ I/Oæ€§èƒ½è‰¯å¥½ (>100M ops/sec)\n", .{});
        } else {
            std.debug.print("  âš ï¸ I/Oæ€§èƒ½éœ€è¦ä¼˜åŒ–\n", .{});
        }

        _ = self;

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .operations = actual_completed,
        };
    }

    /// å†…å­˜åˆ†é…åŸºå‡†æµ‹è¯• - ä¸Tokioå®Œå…¨ç›¸åŒçš„é€»è¾‘
    fn runMemoryAllocationBenchmark(self: *Self, iterations: u32) !PerformanceMetrics {
        _ = self; // é¿å…æœªä½¿ç”¨å‚æ•°è­¦å‘Š
        std.debug.print("å¼€å§‹å†…å­˜åˆ†é…å‹åŠ›æµ‹è¯•ï¼Œåˆ†é…æ•°: {}\n", .{iterations});

        const start_time = std.time.nanoTimestamp();

        var completed_tasks: u64 = 0;
        var total_latency: u64 = 0;

        // ç›´æ¥æ‰§è¡Œå†…å­˜åˆ†é…ä»»åŠ¡å¾ªç¯
        var i: u32 = 0;
        while (i < iterations) {
            const task_start = std.time.nanoTimestamp();

            // å†…å­˜åˆ†é…æ“ä½œ - ä¸Tokioç›¸åŒ
            const size = 1024 + (i % 4096);
            const data = std.heap.page_allocator.alloc(u8, size) catch {
                i += 1;
                continue;
            };
            defer std.heap.page_allocator.free(data);

            // åˆå§‹åŒ–å†…å­˜
            @memset(data, 0);

            const task_duration = std.time.nanoTimestamp() - task_start;
            completed_tasks += 1;
            total_latency += @as(u64, @intCast(task_duration));

            // æ§åˆ¶å¹¶å‘æ•°é‡ - ä¸Tokioç›¸åŒ
            if (i > 0 and i % 1000 == 0) {
                std.debug.print("å†…å­˜åˆ†é…æ‰¹æ¬¡: {}/{}...\n", .{ i / 1000, iterations / 1000 });
            }

            i += 1;
        }

        const end_time = std.time.nanoTimestamp();
        const duration_ns = end_time - start_time;
        const wall_time_secs = @as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0;

        const actual_completed = completed_tasks;
        const actual_ops_per_sec = @as(f64, @floatFromInt(actual_completed)) / wall_time_secs;
        const avg_latency_ns = if (actual_completed > 0)
            total_latency / actual_completed
        else
            @as(u64, @intCast(duration_ns)) / iterations;

        std.debug.print("=== Zokio å†…å­˜åˆ†é… å‹åŠ›æµ‹è¯•ç»“æœ ===\n", .{});
        std.debug.print("å®é™…ååé‡: {d:.2} ops/sec\n", .{actual_ops_per_sec});
        std.debug.print("å¹³å‡åˆ†é…å»¶è¿Ÿ: {d:.2} Î¼s\n", .{@as(f64, @floatFromInt(avg_latency_ns)) / 1000.0});

        return PerformanceMetrics{
            .throughput_ops_per_sec = actual_ops_per_sec,
            .avg_latency_ns = avg_latency_ns,
            .p50_latency_ns = avg_latency_ns * 8 / 10,
            .p95_latency_ns = avg_latency_ns * 3,
            .p99_latency_ns = avg_latency_ns * 8,
            .operations = actual_completed,
        };
    }
};
