//! Zokio ä¼˜åŒ–å†…å­˜åˆ†é…å™¨ v3 - é«˜æ€§èƒ½ç‰ˆæœ¬
//!
//! P2é˜¶æ®µæ€§èƒ½ä¼˜åŒ–ï¼šåº”ç”¨FastSmartAllocatorçš„ä¼˜åŒ–æŠ€æœ¯
//! ç›®æ ‡ï¼šä»238K ops/secæå‡åˆ°5M+ ops/sec

const std = @import("std");
const utils = @import("../utils/utils.zig");

/// ç¼“å­˜è¡Œå¤§å°
const CACHE_LINE_SIZE = 64;

/// ğŸš€ æ— é”é«˜æ€§èƒ½å¯¹è±¡æ±  (P2é˜¶æ®µä¼˜åŒ–)
pub const LockFreeObjectPool = struct {
    const Self = @This();

    // å¯¹è±¡å¤§å°
    object_size: usize,
    // é¢„åˆ†é…çš„å†…å­˜æ± 
    memory_pool: []u8,
    // æ— é”ç©ºé—²é“¾è¡¨å¤´
    free_head: utils.Atomic.Value(?*FreeNode),
    // åŸºç¡€åˆ†é…å™¨
    base_allocator: std.mem.Allocator,
    // åŸå­ç»Ÿè®¡ä¿¡æ¯
    total_allocated: utils.Atomic.Value(usize),
    total_reused: utils.Atomic.Value(usize),

    const FreeNode = extern struct {
        next: ?*FreeNode,
    };

    pub fn init(base_allocator: std.mem.Allocator, object_size: usize, initial_count: usize) !Self {
        // ç¡®ä¿å¯¹è±¡å¤§å°è‡³å°‘èƒ½å®¹çº³FreeNode
        const actual_object_size = @max(object_size, @sizeOf(FreeNode));

        // åˆ†é…è¿ç»­çš„å†…å­˜æ± 
        const pool_size = actual_object_size * initial_count;
        const memory_pool = try base_allocator.alloc(u8, pool_size);

        var self = Self{
            .object_size = actual_object_size,
            .memory_pool = memory_pool,
            .free_head = utils.Atomic.Value(?*FreeNode).init(null),
            .base_allocator = base_allocator,
            .total_allocated = utils.Atomic.Value(usize).init(0),
            .total_reused = utils.Atomic.Value(usize).init(0),
        };

        // åˆå§‹åŒ–æ— é”ç©ºé—²é“¾è¡¨
        self.initializeFreeList(initial_count);

        return self;
    }

    pub fn deinit(self: *Self) void {
        // é‡Šæ”¾å†…å­˜æ± 
        self.base_allocator.free(self.memory_pool);
    }

    /// ğŸš€ æ— é”å¿«é€Ÿåˆ†é…
    pub fn alloc(self: *Self) ![]u8 {
        // æ— é”CASæ“ä½œä»ç©ºé—²é“¾è¡¨è·å–å¯¹è±¡
        while (true) {
            const head = self.free_head.load(.acquire) orelse {
                // ç©ºé—²é“¾è¡¨ä¸ºç©ºï¼Œå›é€€åˆ°åŸºç¡€åˆ†é…å™¨
                _ = self.total_allocated.fetchAdd(1, .monotonic);
                return self.base_allocator.alloc(u8, self.object_size);
            };

            const next = head.next;
            if (self.free_head.cmpxchgWeak(head, next, .acq_rel, .acquire) == null) {
                // æˆåŠŸè·å–å¯¹è±¡
                _ = self.total_reused.fetchAdd(1, .monotonic);
                return @as([*]u8, @ptrCast(head))[0..self.object_size];
            }
            // CASå¤±è´¥ï¼Œé‡è¯•
        }
    }

    /// ğŸš€ æ— é”å¿«é€Ÿé‡Šæ”¾
    pub fn free(self: *Self, memory: []u8) void {
        if (memory.len != self.object_size) {
            // å¤§å°ä¸åŒ¹é…ï¼Œç›´æ¥é‡Šæ”¾
            self.base_allocator.free(memory);
            return;
        }

        // æ£€æŸ¥æ˜¯å¦æ¥è‡ªå†…å­˜æ±  - æ›´å®‰å…¨çš„æ£€æŸ¥
        const pool_start = @intFromPtr(self.memory_pool.ptr);
        const pool_end = pool_start + self.memory_pool.len;
        const mem_addr = @intFromPtr(memory.ptr);

        // æ£€æŸ¥åœ°å€æ˜¯å¦åœ¨æ± èŒƒå›´å†…ä¸”å¯¹é½æ­£ç¡®
        if (mem_addr >= pool_start and mem_addr < pool_end and
            (mem_addr - pool_start) % self.object_size == 0)
        {
            // æ¥è‡ªå†…å­˜æ± ï¼Œæ”¾å›ç©ºé—²é“¾è¡¨
            const node = @as(*FreeNode, @ptrCast(@alignCast(memory.ptr)));

            while (true) {
                const head = self.free_head.load(.acquire);
                node.next = head;

                if (self.free_head.cmpxchgWeak(head, node, .acq_rel, .acquire) == null) {
                    break;
                }
                // CASå¤±è´¥ï¼Œé‡è¯•
            }
        } else {
            // ä¸æ¥è‡ªå†…å­˜æ± ï¼Œç›´æ¥é‡Šæ”¾
            self.base_allocator.free(memory);
        }
    }

    /// åˆå§‹åŒ–æ— é”ç©ºé—²é“¾è¡¨
    fn initializeFreeList(self: *Self, count: usize) void {
        // å°†å†…å­˜æ± åˆ†å‰²ä¸ºå¯¹è±¡å¹¶æ„å»ºç©ºé—²é“¾è¡¨
        var current: ?*FreeNode = null;
        var i: usize = count;

        while (i > 0) {
            i -= 1;
            const offset = i * self.object_size;
            const node = @as(*FreeNode, @ptrCast(@alignCast(self.memory_pool.ptr + offset)));
            node.next = current;
            current = node;
        }

        // è®¾ç½®é“¾è¡¨å¤´
        self.free_head.store(current, .release);
    }

    /// è·å–å¤ç”¨ç‡
    pub fn getReuseRate(self: *const Self) f64 {
        const allocated = self.total_allocated.load(.monotonic);
        const reused = self.total_reused.load(.monotonic);
        const total = allocated + reused;
        if (total == 0) return 0.0;
        return @as(f64, @floatFromInt(reused)) / @as(f64, @floatFromInt(total));
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn getStats(self: *const Self) PoolStats {
        return PoolStats{
            .total_allocated = self.total_allocated.load(.monotonic),
            .total_reused = self.total_reused.load(.monotonic),
            .reuse_rate = self.getReuseRate(),
            .object_size = self.object_size,
        };
    }
};

/// ğŸš€ ä¼˜åŒ–çš„å†…å­˜åˆ†é…å™¨ v3 (P2é˜¶æ®µé«˜æ€§èƒ½ç‰ˆ)
pub const OptimizedAllocator = struct {
    const Self = @This();

    // å°å¯¹è±¡æ±  (8B-256B) - ä½¿ç”¨æ— é”è®¾è®¡
    small_pools: [6]LockFreeObjectPool,
    // åŸºç¡€åˆ†é…å™¨
    base_allocator: std.mem.Allocator,

    pub fn init(base_allocator: std.mem.Allocator) !Self {
        var self = Self{
            .small_pools = undefined,
            .base_allocator = base_allocator,
        };

        // åˆå§‹åŒ–å°å¯¹è±¡æ±  - P2é˜¶æ®µä¼˜åŒ–ï¼šå¢åŠ é¢„åˆ†é…æ•°é‡
        const small_sizes = [_]usize{ 8, 16, 32, 64, 128, 256 };
        for (&self.small_pools, 0..) |*pool, i| {
            const size = small_sizes[i];
            const initial_count = 50000; // P2ä¼˜åŒ–ï¼šé¢„åˆ†é…5ä¸‡ä¸ªå¯¹è±¡ï¼Œæå‡æ€§èƒ½
            pool.* = try LockFreeObjectPool.init(base_allocator, size, initial_count);
        }

        return self;
    }

    pub fn deinit(self: *Self) void {
        for (&self.small_pools) |*pool| {
            pool.deinit();
        }
    }

    pub fn alloc(self: *Self, size: usize) ![]u8 {
        // é€‰æ‹©åˆé€‚çš„å¯¹è±¡æ± 
        if (size <= 256) {
            const pool_index = self.selectPoolIndex(size);
            return self.small_pools[pool_index].alloc();
        }

        // å¤§å¯¹è±¡ç›´æ¥åˆ†é…
        return self.base_allocator.alloc(u8, size);
    }

    pub fn free(self: *Self, memory: []u8) void {
        const size = memory.len;

        // é€‰æ‹©åˆé€‚çš„å¯¹è±¡æ± 
        if (size <= 256) {
            const pool_index = self.selectPoolIndex(size);
            self.small_pools[pool_index].free(memory);
            return;
        }

        // å¤§å¯¹è±¡ç›´æ¥é‡Šæ”¾
        self.base_allocator.free(memory);
    }

    fn selectPoolIndex(self: *Self, size: usize) usize {
        _ = self;
        // ç®€å•çš„å¤§å°æ˜ å°„
        if (size <= 8) return 0;
        if (size <= 16) return 1;
        if (size <= 32) return 2;
        if (size <= 64) return 3;
        if (size <= 128) return 4;
        return 5; // 256å­—èŠ‚
    }

    /// è·å–åˆ†é…å™¨æ¥å£
    pub fn allocator(self: *Self) std.mem.Allocator {
        return std.mem.Allocator{
            .ptr = self,
            .vtable = &.{
                .alloc = allocFn,
                .resize = resizeFn,
                .free = freeFn,
            },
        };
    }

    /// è·å–ä¼˜åŒ–åˆ†é…å™¨ç»Ÿè®¡ä¿¡æ¯
    pub fn getStats(self: *const Self) OptimizedStats {
        var stats = OptimizedStats{
            .total_pools = self.small_pools.len,
            .total_allocated = 0,
            .total_reused = 0,
            .reuse_rate = 0.0,
            .pool_stats = undefined,
        };

        // æ”¶é›†å„ä¸ªæ± çš„ç»Ÿè®¡ä¿¡æ¯
        for (self.small_pools, 0..) |pool, i| {
            const pool_stat = pool.getStats();
            stats.pool_stats[i] = pool_stat;
            stats.total_allocated += pool_stat.total_allocated;
            stats.total_reused += pool_stat.total_reused;
        }

        // è®¡ç®—æ€»ä½“å¤ç”¨ç‡
        const total = stats.total_allocated + stats.total_reused;
        if (total > 0) {
            stats.reuse_rate = @as(f64, @floatFromInt(stats.total_reused)) / @as(f64, @floatFromInt(total));
        }

        return stats;
    }

    // åˆ†é…å™¨æ¥å£å‡½æ•°
    fn allocFn(ctx: *anyopaque, len: usize, ptr_align: u8, ret_addr: usize) ?[*]u8 {
        _ = ptr_align;
        _ = ret_addr;
        const self: *Self = @ptrCast(@alignCast(ctx));
        const memory = self.alloc(len) catch return null;
        return memory.ptr;
    }

    fn resizeFn(ctx: *anyopaque, buf: []u8, buf_align: u8, new_len: usize, ret_addr: usize) bool {
        _ = ctx;
        _ = buf;
        _ = buf_align;
        _ = new_len;
        _ = ret_addr;
        return false; // ä¸æ”¯æŒresize
    }

    fn freeFn(ctx: *anyopaque, buf: []u8, buf_align: u8, ret_addr: usize) void {
        _ = buf_align;
        _ = ret_addr;
        const self: *Self = @ptrCast(@alignCast(ctx));
        self.free(buf);
    }
};

/// å¯¹è±¡æ± ç»Ÿè®¡ä¿¡æ¯
pub const PoolStats = struct {
    total_allocated: usize,
    total_reused: usize,
    reuse_rate: f64,
    object_size: usize,
};

/// ä¼˜åŒ–åˆ†é…å™¨ç»Ÿè®¡ä¿¡æ¯
pub const OptimizedStats = struct {
    total_pools: usize,
    total_allocated: usize,
    total_reused: usize,
    reuse_rate: f64,
    pool_stats: [6]PoolStats,
};
