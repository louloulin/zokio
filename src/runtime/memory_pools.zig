//! ğŸš€ Zokio é«˜æ€§èƒ½å†…å­˜æ± æ¨¡å—
//!
//! é›¶åˆ†é…è¿è¡Œæ—¶è®¾è®¡ï¼š
//! 1. Completionå¯¹è±¡æ±  - é¿å…é¢‘ç¹åˆ†é…
//! 2. ç¼“å†²åŒºæ±  - é¢„åˆ†é…I/Oç¼“å†²åŒº
//! 3. ä»»åŠ¡å¯¹è±¡æ±  - å¤ç”¨ä»»åŠ¡ç»“æ„
//! 4. åŸå­æ— é”è®¾è®¡ - æ”¯æŒå¤šçº¿ç¨‹è®¿é—®

const std = @import("std");
const xev = @import("libxev");
const utils = @import("../utils/utils.zig");

/// ğŸ”§ å†…å­˜æ± é…ç½®
pub const PoolConfig = struct {
    /// Completionæ± å¤§å°
    completion_pool_size: u32 = 1024,

    /// å°ç¼“å†²åŒºæ•°é‡ (4KB)
    small_buffer_count: u32 = 256,

    /// å¤§ç¼“å†²åŒºæ•°é‡ (64KB)
    large_buffer_count: u32 = 64,

    /// å·¨å¤§ç¼“å†²åŒºæ•°é‡ (1MB)
    huge_buffer_count: u32 = 16,

    /// ä»»åŠ¡æ± å¤§å°
    task_pool_size: u32 = 512,

    /// å¯ç”¨ç»Ÿè®¡ä¿¡æ¯
    enable_stats: bool = true,
};

/// ğŸ“Š å†…å­˜æ± ç»Ÿè®¡
pub const PoolStats = struct {
    total_allocations: u64 = 0,
    total_deallocations: u64 = 0,
    current_usage: u64 = 0,
    peak_usage: u64 = 0,
    pool_hits: u64 = 0,
    pool_misses: u64 = 0,

    pub fn recordAllocation(self: *PoolStats, size: u64, from_pool: bool) void {
        self.total_allocations += 1;
        self.current_usage += size;
        self.peak_usage = @max(self.peak_usage, self.current_usage);

        if (from_pool) {
            self.pool_hits += 1;
        } else {
            self.pool_misses += 1;
        }
    }

    pub fn recordDeallocation(self: *PoolStats, size: u64) void {
        self.total_deallocations += 1;
        self.current_usage = if (self.current_usage >= size)
            self.current_usage - size
        else
            0;
    }

    pub fn getHitRate(self: *const PoolStats) f64 {
        const total = self.pool_hits + self.pool_misses;
        if (total == 0) return 0.0;
        return @as(f64, @floatFromInt(self.pool_hits)) / @as(f64, @floatFromInt(total));
    }
};

/// ğŸš€ åŸå­æ ˆå®ç° (æ— é”)
fn AtomicStack(comptime T: type) type {
    return struct {
        const Self = @This();
        const Node = struct {
            next: ?*Node,
            data: T,
        };

        head: std.atomic.Value(?*Node) = std.atomic.Value(?*Node).init(null),

        pub fn push(self: *Self, node: *Node) void {
            var current_head = self.head.load(.acquire);
            while (true) {
                node.next = current_head;
                if (self.head.cmpxchgWeak(current_head, node, .release, .acquire)) |new_head| {
                    current_head = new_head;
                } else {
                    break;
                }
            }
        }

        pub fn pop(self: *Self) ?*Node {
            var current_head = self.head.load(.acquire);
            while (current_head) |head| {
                const next = head.next;
                if (self.head.cmpxchgWeak(current_head, next, .release, .acquire)) |new_head| {
                    current_head = new_head;
                } else {
                    return head;
                }
            }
            return null;
        }
    };
}

/// ğŸš€ Completionå¯¹è±¡æ± 
pub const CompletionPool = struct {
    const Self = @This();
    const CompletionNode = AtomicStack(xev.Completion).Node;

    /// é¢„åˆ†é…çš„Completionæ•°ç»„
    completions: []CompletionNode,

    /// ç©ºé—²æ ˆ
    free_stack: AtomicStack(xev.Completion),

    /// ç»Ÿè®¡ä¿¡æ¯
    stats: PoolStats = .{},

    /// åˆ†é…å™¨
    allocator: std.mem.Allocator,

    pub fn init(allocator: std.mem.Allocator, config: PoolConfig) !Self {
        const completions = try allocator.alloc(CompletionNode, config.completion_pool_size);

        var pool = Self{
            .completions = completions,
            .free_stack = AtomicStack(xev.Completion){},
            .allocator = allocator,
        };

        // åˆå§‹åŒ–æ‰€æœ‰Completionå¹¶åŠ å…¥ç©ºé—²æ ˆ
        for (completions) |*completion| {
            completion.data = xev.Completion{};
            pool.free_stack.push(completion);
        }

        return pool;
    }

    pub fn deinit(self: *Self) void {
        self.allocator.free(self.completions);
    }

    /// ğŸš€ è·å–Completionå¯¹è±¡
    pub fn acquire(self: *Self) ?*xev.Completion {
        if (self.free_stack.pop()) |node| {
            self.stats.recordAllocation(@sizeOf(xev.Completion), true);
            return &node.data;
        }

        // æ± å·²ç©ºï¼Œè®°å½•miss
        self.stats.recordAllocation(@sizeOf(xev.Completion), false);
        return null;
    }

    /// ğŸš€ é‡Šæ”¾Completionå¯¹è±¡
    pub fn release(self: *Self, completion: *xev.Completion) void {
        // é‡ç½®CompletionçŠ¶æ€ - ä½¿ç”¨é»˜è®¤åˆå§‹åŒ–è€Œä¸æ˜¯zeroes
        completion.* = xev.Completion{};

        // è®¡ç®—èŠ‚ç‚¹åœ°å€
        const node_ptr: *CompletionNode = @fieldParentPtr("data", completion);

        // è¿”å›åˆ°ç©ºé—²æ ˆ
        self.free_stack.push(node_ptr);

        self.stats.recordDeallocation(@sizeOf(xev.Completion));
    }

    /// ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn getStats(self: *const Self) PoolStats {
        return self.stats;
    }
};

/// ğŸš€ ç¼“å†²åŒºæ± 
pub const BufferPool = struct {
    const Self = @This();

    /// ç¼“å†²åŒºå¤§å°ç±»å‹
    pub const BufferSize = enum {
        small, // 4KB
        large, // 64KB
        huge, // 1MB

        pub fn getSize(self: BufferSize) u32 {
            return switch (self) {
                .small => 4 * 1024,
                .large => 64 * 1024,
                .huge => 1024 * 1024,
            };
        }
    };

    const BufferNode = struct {
        next: ?*BufferNode,
        data: []u8,
    };

    /// å°ç¼“å†²åŒºæ± 
    small_buffers: []u8,
    small_nodes: []BufferNode,
    small_stack: AtomicStack([]u8),

    /// å¤§ç¼“å†²åŒºæ± 
    large_buffers: []u8,
    large_nodes: []BufferNode,
    large_stack: AtomicStack([]u8),

    /// å·¨å¤§ç¼“å†²åŒºæ± 
    huge_buffers: []u8,
    huge_nodes: []BufferNode,
    huge_stack: AtomicStack([]u8),

    /// ç»Ÿè®¡ä¿¡æ¯
    stats: PoolStats = .{},

    /// åˆ†é…å™¨
    allocator: std.mem.Allocator,

    pub fn init(allocator: std.mem.Allocator, config: PoolConfig) !Self {
        // åˆ†é…å°ç¼“å†²åŒº
        const small_size = BufferSize.small.getSize();
        const small_buffers = try allocator.alloc(u8, small_size * config.small_buffer_count);
        const small_nodes = try allocator.alloc(BufferNode, config.small_buffer_count);

        // åˆ†é…å¤§ç¼“å†²åŒº
        const large_size = BufferSize.large.getSize();
        const large_buffers = try allocator.alloc(u8, large_size * config.large_buffer_count);
        const large_nodes = try allocator.alloc(BufferNode, config.large_buffer_count);

        // åˆ†é…å·¨å¤§ç¼“å†²åŒº
        const huge_size = BufferSize.huge.getSize();
        const huge_buffers = try allocator.alloc(u8, huge_size * config.huge_buffer_count);
        const huge_nodes = try allocator.alloc(BufferNode, config.huge_buffer_count);

        var pool = Self{
            .small_buffers = small_buffers,
            .small_nodes = small_nodes,
            .small_stack = AtomicStack([]u8){},
            .large_buffers = large_buffers,
            .large_nodes = large_nodes,
            .large_stack = AtomicStack([]u8){},
            .huge_buffers = huge_buffers,
            .huge_nodes = huge_nodes,
            .huge_stack = AtomicStack([]u8){},
            .allocator = allocator,
        };

        // åˆå§‹åŒ–å°ç¼“å†²åŒºæ ˆ
        for (0..config.small_buffer_count) |i| {
            const start = i * small_size;
            const end = start + small_size;
            small_nodes[i].data = small_buffers[start..end];
            pool.small_stack.push(@ptrCast(&small_nodes[i]));
        }

        // åˆå§‹åŒ–å¤§ç¼“å†²åŒºæ ˆ
        for (0..config.large_buffer_count) |i| {
            const start = i * large_size;
            const end = start + large_size;
            large_nodes[i].data = large_buffers[start..end];
            pool.large_stack.push(@ptrCast(&large_nodes[i]));
        }

        // åˆå§‹åŒ–å·¨å¤§ç¼“å†²åŒºæ ˆ
        for (0..config.huge_buffer_count) |i| {
            const start = i * huge_size;
            const end = start + huge_size;
            huge_nodes[i].data = huge_buffers[start..end];
            pool.huge_stack.push(@ptrCast(&huge_nodes[i]));
        }

        return pool;
    }

    pub fn deinit(self: *Self) void {
        self.allocator.free(self.small_buffers);
        self.allocator.free(self.small_nodes);
        self.allocator.free(self.large_buffers);
        self.allocator.free(self.large_nodes);
        self.allocator.free(self.huge_buffers);
        self.allocator.free(self.huge_nodes);
    }

    /// ğŸš€ è·å–æŒ‡å®šå¤§å°çš„ç¼“å†²åŒº
    pub fn acquire(self: *Self, size: BufferSize) ?[]u8 {
        const stack = switch (size) {
            .small => &self.small_stack,
            .large => &self.large_stack,
            .huge => &self.huge_stack,
        };

        if (stack.pop()) |node_ptr| {
            const node: *BufferNode = @ptrCast(node_ptr);
            self.stats.recordAllocation(node.data.len, true);
            return node.data;
        }

        self.stats.recordAllocation(size.getSize(), false);
        return null;
    }

    /// ğŸš€ é‡Šæ”¾ç¼“å†²åŒº
    pub fn release(self: *Self, buffer: []u8) void {
        const size = buffer.len;

        // ç¡®å®šç¼“å†²åŒºç±»å‹
        const buffer_size = if (size <= BufferSize.small.getSize())
            BufferSize.small
        else if (size <= BufferSize.large.getSize())
            BufferSize.large
        else
            BufferSize.huge;

        // æ‰¾åˆ°å¯¹åº”çš„èŠ‚ç‚¹
        const nodes = switch (buffer_size) {
            .small => self.small_nodes,
            .large => self.large_nodes,
            .huge => self.huge_nodes,
        };

        const stack = switch (buffer_size) {
            .small => &self.small_stack,
            .large => &self.large_stack,
            .huge => &self.huge_stack,
        };

        // æŸ¥æ‰¾åŒ¹é…çš„èŠ‚ç‚¹
        for (nodes) |*node| {
            if (node.data.ptr == buffer.ptr) {
                stack.push(@ptrCast(node));
                self.stats.recordDeallocation(size);
                return;
            }
        }

        // å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„èŠ‚ç‚¹ï¼Œè¯´æ˜è¿™ä¸æ˜¯ä»æ± ä¸­åˆ†é…çš„ç¼“å†²åŒº
        // è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬åªè®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.stats.recordDeallocation(size);
    }

    /// ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn getStats(self: *const Self) PoolStats {
        return self.stats;
    }
};

/// ğŸš€ ç»Ÿä¸€å†…å­˜æ± ç®¡ç†å™¨
pub const MemoryPoolManager = struct {
    const Self = @This();

    /// Completionæ± 
    completion_pool: CompletionPool,

    /// ç¼“å†²åŒºæ± 
    buffer_pool: BufferPool,

    /// é…ç½®
    config: PoolConfig,

    pub fn init(allocator: std.mem.Allocator, config: PoolConfig) !Self {
        return Self{
            .completion_pool = try CompletionPool.init(allocator, config),
            .buffer_pool = try BufferPool.init(allocator, config),
            .config = config,
        };
    }

    pub fn deinit(self: *Self) void {
        self.completion_pool.deinit();
        self.buffer_pool.deinit();
    }

    /// ğŸ“Š è·å–ç»¼åˆç»Ÿè®¡ä¿¡æ¯
    pub fn getStats(self: *const Self) MemoryPoolStats {
        return MemoryPoolStats{
            .completion_stats = self.completion_pool.getStats(),
            .buffer_stats = self.buffer_pool.getStats(),
        };
    }
};

/// ğŸ“Š ç»¼åˆå†…å­˜æ± ç»Ÿè®¡
pub const MemoryPoolStats = struct {
    completion_stats: PoolStats,
    buffer_stats: PoolStats,

    pub fn getTotalAllocations(self: *const MemoryPoolStats) u64 {
        return self.completion_stats.total_allocations +
            self.buffer_stats.total_allocations;
    }

    pub fn getOverallHitRate(self: *const MemoryPoolStats) f64 {
        const total_hits = self.completion_stats.pool_hits + self.buffer_stats.pool_hits;
        const total_misses = self.completion_stats.pool_misses + self.buffer_stats.pool_misses;
        const total = total_hits + total_misses;

        if (total == 0) return 0.0;
        return @as(f64, @floatFromInt(total_hits)) / @as(f64, @floatFromInt(total));
    }
};

/// ğŸ§ª å†…å­˜æ± æµ‹è¯•
pub fn runMemoryPoolTest(allocator: std.mem.Allocator) !void {
    std.debug.print("\n=== ğŸš€ å†…å­˜æ± æ€§èƒ½æµ‹è¯• ===\n", .{});

    const config = PoolConfig{
        .completion_pool_size = 1024,
        .small_buffer_count = 256,
        .large_buffer_count = 64,
        .huge_buffer_count = 16,
    };

    var pool_manager = try MemoryPoolManager.init(allocator, config);
    defer pool_manager.deinit();

    // æ€§èƒ½æµ‹è¯•
    const iterations = 100000;
    const start_time = std.time.nanoTimestamp();

    for (0..iterations) |_| {
        // æµ‹è¯•Completionæ± 
        if (pool_manager.completion_pool.acquire()) |completion| {
            pool_manager.completion_pool.release(completion);
        }

        // æµ‹è¯•ç¼“å†²åŒºæ± 
        if (pool_manager.buffer_pool.acquire(.small)) |buffer| {
            pool_manager.buffer_pool.release(buffer);
        }
    }

    const end_time = std.time.nanoTimestamp();
    const duration_ns = end_time - start_time;
    const ops_per_sec = @as(f64, @floatFromInt(iterations * 2)) /
        (@as(f64, @floatFromInt(duration_ns)) / 1_000_000_000.0);

    const stats = pool_manager.getStats();

    std.debug.print("å†…å­˜æ± æµ‹è¯•ç»“æœ:\n", .{});
    std.debug.print("  æ€»æ“ä½œæ•°: {}\n", .{iterations * 2});
    std.debug.print("  æ± å‘½ä¸­ç‡: {d:.2}%\n", .{stats.getOverallHitRate() * 100});
    std.debug.print("  æ€§èƒ½: {d:.0} ops/sec\n", .{ops_per_sec});
    std.debug.print("  âœ… å†…å­˜æ± æµ‹è¯•å®Œæˆ\n", .{});
}
